---
title: 'Advanced Statistical Modelling: Logistic Regression'
author: "Ricard Meyerhofer & Joel Cantero"
date: "4/11/2019"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---


## Exploratory data analysis
As explained in the problem statement, our dataset is composed by 28645 calls from JYB. JYB has the purpose of reducing the telemarketing costs by decreasing the number of calls to clients not likely to buy the product. This is the list of the available variables:

Variable  | Description                           | Attribute type
:--------------:|:-----------------------------------------------------------------------------------:|:--------------:
id | Customer ID |  Client |
age | age in years |  Client|
job | (admin., blue-collar, entrepreneur, housemaid, management, retired, self-employed, services, student, technician, unemployed, unknown) |  Client |
marital | Marital status (Divorced, married, single, unknown) | Client |
education | Education level (basic.4y, basic.6y, basic.9y, high.school, illiterate, professional.course, university.degree, unknown) |  Client |
default | is he/she a defaulter? (No, yes, unknown) |  Client |
housing | does he/she has a mortgage? (No, yes, unknown) | Client |
loan | does he/she has a personal loan? (No, yes, unknown) | Client |
contact | phone type (cellular, telephone) | Call |
month | month of the call | Call |
day_of_week | day of the call (mon, tue, wed, thu, fri) | Call |
campaign | does he/she has a personal loan? (No, yes, unknown) | Campaign |
pdays | does he/she has a personal loan? (No, yes, unknown) | Campaign |
previous | does he/she has a personal loan? (No, yes, unknown) | Campaign |
poutcome | does he/she has a personal loan? (No, yes, unknown) | Campaign |
emp.var.rate | employment variation rate (quarterly) | Indicators  |
cons.price.idx | Consumer Price Index (monthly) | Indicators |
cons.conf.idx | Consumer confidence index (monthly) | Indicators |
euribor3m | euribor a 3 mesos (daily) | Indicators |
nr.employed  | number of employed (quarterly) | Indicators | 
Y | The customer subscribed the deposit? (yes,no) | Response |

```{r, include=FALSE}
library(mice)
library(VIM)
library(DMwR)
library(heplots)
library(ggrepel)
library(ggplot2)
library(missForest)
require(robustbase)
library(missMDA)

library(caret) # models
library(corrplot) # correlation plots
library(DALEX) # explain models
library(DescTools) # plots
library(doParallel) # parellel processing
library(dplyr) # syntax
#library(ggbiplot) # PCA plots
library(ggplot2) # plots
library(readr)
library(inspectdf) # data overview
library(sjPlot) # contingency tables
library(tabplot) # data overview
``` 

```{r, fig.height=3, fig.width=12, message=FALSE, warning=FALSE, include=FALSE}
dataset <- read_csv(file="JYB.csv", header = T, sep = ";")
col_types= cols(
  id = col_double(),
  age = col_double(),
  job = col_character(),
  marital = col_character(),
  education = col_character(),
  default = col_character(),
  housing = col_character(),
  loan = col_character(),
  contact = col_character(),
  month = col_character(),
  day_of_week = col_double(),
  campaign = col_double(),
  pdays = col_double(),
  previous = col_double(),
  poutcome = col_character(),
  emp.var.rate = col_double(),
  cons.price.idx = col_double(),
  cons.conf.idx = col_double(),
  euribor3m =col_double(),
  nr.employed = col_double(), 
  y = col_character()
))
aggr(dataset, numbers=TRUE, sortVars=TRUE, labels=names(dataset), 
                  ylab=c("Histogram of missing data","Pattern"))[1]
``` 

As we can see we have that all our variables are integers or factors. We have seen that there our dataset is complete which means that it has no missing values. However, this does not imply that there are no outliers.


```{r, echo=FALSE, fig.height=3, fig.width=12, message=FALSE, warning=FALSE}
inspect_cat(dataset, show_plot = TRUE)
```
```{r, echo=FALSE, fig.height=6, fig.width=12, message=FALSE, warning=FALSE}
inspect_num(dataset)
```

```{r, echo=FALSE, fig.height=6, fig.width=12, message=FALSE, warning=FALSE}
prop.table(table(dataset$y))

cor(dataset$previous, dataset$pdays)
```

Dataset is UNbalanced. Resampling is required

```{r, echo=FALSE, fig.height=6, fig.width=12, message=FALSE, warning=FALSE}
ggplot( dataset %>%
          group_by(previous, y) %>%
          tally(),
          aes(previous, n, fill = y)
      ) +
      geom_col() +
      theme_bw()
```
```{r, echo=FALSE, fig.height=6, fig.width=12, message=FALSE, warning=FALSE}
tableplot(dataset, sortCol = y)
```
```{r, echo=FALSE, fig.height=6, fig.width=12, message=FALSE, warning=FALSE}

inspect_cor(dataset, show_plot = TRUE)

df_cor <- select_if(dataset, is.numeric) %>% cor()
corrplot(df_cor, method = "number")

```


```{r}
# select categorical variables
df_cat <- select_if(dataset, is.character) %>% names()
# remove the response
response_ind <- match('y', df_cat)
df_cat <- df_cat[-response_ind]

# plot categorical variables
for (i in df_cat) {
  print(i)
  
  print(
    sjp.xtab(df$deposit,
         df[[i]],
         margin = "row",
         bar.pos = "stack",
         axis.titles = "deposit",
         legend.title = i)
  )
}
```
## With the original variables, fit the complete model without interactions and using the logit link function.
In this section we are going to perform a logistic regression model with all the variables without interactions. We are going to exclude id because it is a identificator number. The logit link is the default for the binomial family so doesnâ€™t need to be specified. To evaluate the model, we have splitten our dataset into training sample (90%) and test sample (10%). We will calculate accuracy model for each model that we build, it is necessary to compare models. 

```{r, echo=TRUE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE, results = 'hide'}

levels(dataset$y) <- c(FALSE,TRUE)
dataset$y <- as.logical.factor(dataset$y)

# Split train and test 
require(caTools)
library(caTools)
sample <- sample.split(dataset,SplitRatio = 0.90)
train <- subset(dataset,sample==TRUE)
test <- subset(dataset, sample==FALSE)

summary(completeModel<-glm(y ~ . - id - y, train, family = binomial))


# Predictions
completeModel$xlevels[["euribor3m"]] <- union(completeModel$xlevels[["euribor3m"]], levels(test$euribor3m))
preds <- predict(completeModel, test, type = "response")
preds[preds > .5] = TRUE
preds[preds < .5] = FALSE
preds <- as.logical(preds)
mean(preds == test$y)

```

As we can see, we obtain a 86.65% accuracy in our test set. 

```{r, echo=TRUE, message=FALSE, warning=FALSE, fig.height=6, fig.width=12}
plot(completeModel)
op<-par(mfrow=c(2,2))

```

## Evaluate possible first order interactions (between two factors or between a factor and a covariable) and include them in the model (if there were any).

```{r, echo=TRUE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE, results = 'hide'}

cor(dataset)
require(sjPlot)
library(sjPlot)
sjt(dataset)
summary(interactionsModel<-glm(y ~ (. - id - y) + cons.price.idx*cons.conf.idx + job*education, train, family = binomial))

interactionsModel$xlevels[["euribor3m"]] <- union(interactionsModel$xlevels[["euribor3m"]], levels(test$euribor3m))
preds <- predict(interactionsModel, test, type = "response")
preds[preds > .5] = TRUE
preds[preds < .5] = FALSE
preds <- as.logical(preds)

mean(preds == test$y)


# BIC criterion
forwardModel <- step(nullModel, scope = list(upper=completeModel), direction="both", criterion = "BIC", k=log(nrow(dataset)))

backwardModel <- step(completeModel,
scope = list(lower=nullModel),
direction="both",
criterion = "BIC",
k=log(nrow(dataset)))
AICModel <- step(completeModel, 
                      scope = list(lower=nullModel), 
                      direction="forward", 
                      criterion = "AIC", 
                      k=log(nrow(dataset)))

AICModel <- stepAIC(completeModel, 
                      scope = list(lower=nullModel), 
                      direction="forward", 
                      criterion = "AIC", 
                      k=log(nrow(dataset)))

``` 
## Perform an automatic variables selection basen on the AIC & BIC. Make a comparison of the models and argue which one is chosen.

In order to create a model with the most significant variables, we decided to choose both criterions: the BIC and AIC criterion. Then, we will make a comparision of the models to select which one is better.

There are two heuristic strategies when modelling: 

- **Forward:** In this strategy we start the case with none available predictor variables and add one at a time

- **Backward:** In this strategy we start with all available predictor variables and delete one at a
time

In this case, due the amount of variables we have on our dataset, we rather follow forward heuristic strategy. Just because if we try to follow backward model it lasts very longer.

```{r, echo=TRUE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE, results = 'hide'}
nullModel <- lm(y ~ 1, train)

# BIC criterion
BICModel <- step(nullModel, scope = list(lower=nullModel, upper=completeModel), direction="both", criterion = "BIC", k=log(nrow(train)))

preds <- predict(BICModel, test, type = "response")
preds[preds > .5] = TRUE
preds[preds < .5] = FALSE
preds <- as.logical(preds)
mean(preds == test$y)

# AIC BIC Model = -56410.7
# Accuracy: 89,07%
# formula = y ~ cons.conf.idx + poutcome + contact + pdays
require(MASS)
library(MASS)
AICModel <- stepAIC(nullModel, scope = list(lower=nullModel, upper=completeModel),
        direction = "both",
        trace = 1, 
        k = log(nrow(train)))
preds <- predict(AICModel, test, type = "response")
preds[preds > .5] = TRUE
preds[preds < .5] = FALSE
preds <- as.logical(preds)

mean(preds == test$y)

``` 

As we can see, both criterias give us the same formula (y ~ cons.conf.idx + poutcome + contact + pdays) and accordingly the same accuracy. Both have an R-squared of around 0.206 so their performance is similar. 

## Validate the model by checking the assumptions
Once we have our model selected, we are going to validate it with anova comparing the null model with our
final model.


```{r, echo=TRUE, fig.height=2, fig.width=12, message=FALSE, warning=FALSE, fig.align='center'}
anova(nullModel, AICModel)
```
In this case we can see that our model, passes the test since our p-value is lower than 0.05.

## Interpret the final model