---
title: 'Advanced Statistical Modelling: Logistic Regression'
geometry: margin=1.75cm
author: "Ricard Meyerhofer & Joel Cantero"
date: "4/11/2019"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---


## Exploratory data analysis
As explained in the problem statement, our dataset is composed by 28645 calls from JYB. JYB has the purpose of reducing the telemarketing costs by decreasing the number of calls to clients not likely to buy the product. This is the list of the available variables:

Variable  | Description                           | Attribute type
:--------------:|:--------------------------------------------------------------------------------------:|:------:
id | Customer ID |  Client |
age | age in years |  Client|
job | (admin., blue-collar, entrepreneur, housemaid, management, retired, self-employed, services, student, technician, unemployed, unknown) |  Client |
marital | Marital status (Divorced, married, single, unknown) | Client |
education | Education level (basic.4y, basic.6y, basic.9y, high.school, illiterate, professional.course, university.degree, unknown) |  Client |
default | is he/she a defaulter? (No, yes, unknown) |  Client |
housing | does he/she has a mortgage? (No, yes, unknown) | Client |
loan | does he/she has a personal loan? (No, yes, unknown) | Client |
contact | phone type (cellular, telephone) | Call |
month | month of the call | Call |
day_of_week | day of the call (mon, tue, wed, thu, fri) | Call |
campaign | Number of contacts made this campaign for this client (including the current one) | Campaign |
pdays | number of days that have passed since the customer was contacted for the last time for a previous campaign (999 means that it was not previously contacted) | Campaign |
previous | number of calls made to this client before this campaign | Campaign |
poutcome | previous campaign result (failure, nonexistent, success) | Campaign |
emp.var.rate | employment variation rate (quarterly) | Indicators  |
cons.price.idx | Consumer Price Index (monthly) | Indicators |
cons.conf.idx | Consumer confidence index (monthly) | Indicators |
euribor3m | euribor a 3 mesos (daily) | Indicators |
nr.employed  | number of employed (quarterly) | Indicators | 
Y | The customer subscribed the deposit? (yes,no) | Response |

```{r, include=FALSE}
library(mice)
library(VIM)
library(DMwR)
library(heplots)
library(ggrepel)
library(ggplot2)
library(missForest)
require(robustbase)
library(missMDA)

library(caret) # models
library(corrplot) # correlation plots
library(DALEX) # explain models
library(DescTools) # plots
library(doParallel) # parellel processing
library(dplyr) # syntax
library(ggbiplot) # PCA plots
library(ggplot2) # plots
library(tidyverse)
library(devtools)
library(readr)
library(inspectdf) # data overview
library(sjPlot) # contingency tables
library(tabplot) # data overview
``` 

```{r, fig.height=3, fig.width=12, message=FALSE, warning=FALSE, include=FALSE}
dataset <- read.csv(file="JYB.csv", header = T, sep = ";", colClasses = c(
  "id" = "double",
  "age" = "double",
  "job" = "character",
  "marital" = "character",
  "education" = "character",
  "default" = "character",
  "housing" = "character",
  "loan" = "character",
  "contact" = "character",
  "month" = "character",
  "day_of_week" = "character",
  "campaign" = "double",
  "pdays" = "double",
  "previous" = "double",
  "poutcome" = "character",
  "emp.var.rate" = "double",
  "cons.price.idx" = "double",
  "cons.conf.idx" = "double",
  "euribor3m" ="double",
  "nr.employed" = "double", 
  "y" = "character"
))
aggr(dataset, numbers=TRUE, sortVars=TRUE, labels=names(dataset), 
                  ylab=c("Histogram of missing data","Pattern"))[1]
``` 

As we can see in the plot, we have 11 factors and 10 numeric values. Furthermore, we have seen that there our dataset is complete which means that it has no missing values. However, this does not imply that there are no outliers.
```{r, echo=FALSE, fig.height=4.0, fig.width=12}
# barplot of column types
x <- inspect_types(dataset)
show_plot(x)
```


Exploration of the categorical variables where we can see a map with all their possible values and their representation. We can see that there is a clear unbalance in some variables such as $poutcome$, $load$, $contact$ or the response variable $y$.  So we might need to resample our dataset. 

```{r, echo=FALSE, fig.height=6, fig.width=12}
x <- inspect_cat(dataset)
show_plot(x)
```

If we now explore of the numerical variables, we see that most of variables are not following a normal. This might be because they are ratios and also are taken most of them in a monthly basis. 

```{r, echo=FALSE, fig.height=6, fig.width=12, message=FALSE, warning=FALSE,results='hide'}
x <- inspect_num(dataset)
show_plot(x)
```

We can also see that the correlation between the variable $previous$ and $pdays$ is of 0.50 which means that they are moderately correlated. But if we pay attention to number of 0's and 999 and their description, we can see that they are describing the same thing. So we are going to see how these variables are related to the response variable and as we can see below, $pdays$ is not necessary.

```{r, echo=FALSE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE}
df_cor <- select_if(dataset, is.numeric) %>% cor()
```

```{r, echo=FALSE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE}
par(fig=c(0,0.8,0,0.8), new=TRUE)
ggplot( dataset %>%
          group_by(previous, y) %>%
          tally(),
          aes(previous, n, fill = y)
      ) +
      geom_col() +
      theme_bw()
corrplot(df_cor, method = "number")
```

Also we can do a general plot to have a first idea of which variables help us to distinguish between the two groups. As we can see below, it looks like $housing$, $contact$ and $potcome$ distinguish between the two groups.

```{r, echo=FALSE, fig.height=6, fig.width=12, message=FALSE, warning=FALSE}
tableplot(dataset, sortCol = y)
```


```{r, echo=FALSE, fig.height=6, fig.width=12}
# select categorical variables
df_cat <- select_if(dataset, is.character) %>% names()
response_ind <- match('y', df_cat)
df_cat <- df_cat[-response_ind]

par(mfrow=c(5,2))

# plot categorical variables
for (i in df_cat) {
  par(mfrow=c(5,2))
  print(
    sjp.xtab(dataset$y,
         dataset[[i]],
         margin = "row",
         bar.pos = "stack",
         axis.titles = "deposit",
         legend.title = i)
  )
}
```


```{r, echo=FALSE, fig.height=6, fig.width=12}
# keep numeric variables
df_numeric <- select_if(dataset, is.numeric)

pca <- prcomp(df_numeric, scale = T )

# display components
pca

# variance
pr_var <- (pca$sdev)^2 

# % of variance explained
prop_varex <- pr_var/sum(pr_var)

# show percentage of variance of each component
plot(prop_varex,
     xlab = "Principal Component",
     ylab = "Proportion of Variance Explained",
     type = "b" )


# Scree Plot
plot(cumsum(prop_varex),
     xlab = "Principal Component",
     ylab = "Cumulative Proportion of Variance Explained",
     type = "b" )

library(devtools)
ggbiplot(pca,
         ellipse = TRUE,
         alpha = 0.2,
         groups = dataset$y) +
  theme_bw()


ggbiplot(pca,
         choices = c(3, 4),
         ellipse = TRUE,
         alpha = 0.2,
         groups = dataset$y) +
  theme_bw()
```

## With the original variables, fit the complete model without interactions and using the logit link function.
In this section we are going to perform a logistic regression model with all the variables without interactions. We are going to exclude id because it is a identificator number. The logit link is the default for the binomial family so doesnâ€™t need to be specified. To evaluate the model, we have splitten our dataset into training sample (90%) and test sample (10%). We will calculate accuracy model for each model that we build, it is necessary to compare models. 

```{r, echo=TRUE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE, results = 'hide'}

levels(dataset$y) <- c(FALSE,TRUE)
dataset$y <- as.logical.factor(dataset$y)

# Split train and test 
require(caTools)
library(caTools)
sample <- sample.split(dataset,SplitRatio = 0.90)
train <- subset(dataset,sample==TRUE)
test <- subset(dataset, sample==FALSE)

summary(completeModel<-glm(y ~ . - id - y, train, family = binomial))


# Predictions
completeModel$xlevels[["euribor3m"]] <- union(completeModel$xlevels[["euribor3m"]], levels(test$euribor3m))
preds <- predict(completeModel, test, type = "response")
preds[preds > .5] = TRUE
preds[preds < .5] = FALSE
preds <- as.logical(preds)
mean(preds == test$y)

```

As we can see, we obtain a 86.65% accuracy in our test set. 

```{r, echo=TRUE, message=FALSE, warning=FALSE, fig.height=6, fig.width=12}
plot(completeModel)
op<-par(mfrow=c(2,2))

```

## Evaluate possible first order interactions (between two factors or between a factor and a covariable) and include them in the model (if there were any).

```{r, echo=TRUE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE, results = 'hide'}

cor(dataset)
require(sjPlot)
library(sjPlot)
sjt(dataset)
summary(interactionsModel<-glm(y ~ (. - id - y) + cons.price.idx*cons.conf.idx + job*education, train, family = binomial))

interactionsModel$xlevels[["euribor3m"]] <- union(interactionsModel$xlevels[["euribor3m"]], levels(test$euribor3m))
preds <- predict(interactionsModel, test, type = "response")
preds[preds > .5] = TRUE
preds[preds < .5] = FALSE
preds <- as.logical(preds)

mean(preds == test$y)


# BIC criterion
forwardModel <- step(nullModel, scope = list(upper=completeModel), direction="both", criterion = "BIC", k=log(nrow(dataset)))

backwardModel <- step(completeModel,
scope = list(lower=nullModel),
direction="both",
criterion = "BIC",
k=log(nrow(dataset)))
AICModel <- step(completeModel, 
                      scope = list(lower=nullModel), 
                      direction="forward", 
                      criterion = "AIC", 
                      k=log(nrow(dataset)))

AICModel <- stepAIC(completeModel, 
                      scope = list(lower=nullModel), 
                      direction="forward", 
                      criterion = "AIC", 
                      k=log(nrow(dataset)))

``` 
## Perform an automatic variables selection basen on the AIC & BIC. Make a comparison of the models and argue which one is chosen.

In order to create a model with the most significant variables, we decided to choose both criterions: the BIC and AIC criterion. Then, we will make a comparision of the models to select which one is better.

There are two heuristic strategies when modelling: 

- **Forward:** In this strategy we start the case with none available predictor variables and add one at a time

- **Backward:** In this strategy we start with all available predictor variables and delete one at a
time

In this case, due the amount of variables we have on our dataset, we rather follow forward heuristic strategy. Just because if we try to follow backward model it lasts very longer.

```{r, echo=TRUE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE, results = 'hide'}
nullModel <- lm(y ~ 1, train)

# BIC criterion
BICModel <- step(nullModel, scope = list(lower=nullModel, upper=completeModel), direction="both", criterion = "BIC", k=log(nrow(train)))

preds <- predict(BICModel, test, type = "response")
preds[preds > .5] = TRUE
preds[preds < .5] = FALSE
preds <- as.logical(preds)
mean(preds == test$y)

# AIC BIC Model = -56410.7
# Accuracy: 89,07%
# formula = y ~ cons.conf.idx + poutcome + contact + pdays
require(MASS)
library(MASS)
AICModel <- stepAIC(nullModel, scope = list(lower=nullModel, upper=completeModel),
        direction = "both",
        trace = 1, 
        k = log(nrow(train)))
preds <- predict(AICModel, test, type = "response")
preds[preds > .5] = TRUE
preds[preds < .5] = FALSE
preds <- as.logical(preds)

mean(preds == test$y)

``` 

As we can see, both criterias give us the same formula (y ~ cons.conf.idx + poutcome + contact + pdays) and accordingly the same accuracy. Both have an R-squared of around 0.206 so their performance is similar. 

## Validate the model by checking the assumptions
Once we have our model selected, we are going to validate it with anova comparing the null model with our
final model.


```{r, echo=TRUE, fig.height=2, fig.width=12, message=FALSE, warning=FALSE, fig.align='center'}
anova(nullModel, AICModel)
```
In this case we can see that our model, passes the test since our p-value is lower than 0.05.

## Interpret the final model

