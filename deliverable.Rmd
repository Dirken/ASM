---
title: 'Advanced Statistical Modelling: Linear Models'
author: "Joel Cantero Priego and Ricard Meyerhofer Parra"
date: "12/10/2019"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library("kableExtra")

```

## Introduction

In this assignment, we are going to use the IMDB dataset. This IMDB dataset, contains information of 940 films released between 2000 and 2016. The data has been obtained from the IMDB's webpage. The following is a list where we can see all the variables of the dataset:

Variable name         | Description                          | Values
:--------------:|:-------------------------------------:|:-------------------------------------:
movietitle| Director of the given title | String |
gross| Gross in dollars |	Integer |
budget|Budget in dollars	| Integer |
duration| Film duration in minutes | Integer |
titleyear| The release year of the title	| Integer |
directorfl| Director Facebook likes	| Integer |
actor1fl| Actor 1 Facebook likes | Integer |
actor2fl| Actor 2 Facebook likes | Integer |
actor3fl| Actor 3 Facebook likes | Integer |
castfl| Cast Facebook likes | Integer |
facenumber_in_poster| Number of faces that appears in the poster | Integer |
genre | Genre film | Action/Comedy/Drama/Terror

As we can see we have that all our variables are numerical in exception genre. This dataset is complete which means that it has no missing values. However, this does not imply that there are no outliers.

```{r read-data, include=FALSE}
dataset=read.csv2("IMDB.csv")
head(dataset)
summary(dataset)
```

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(mice)
md.pattern(dataset)
```

As required in the assignment, we are going to create a categorical variable: **yearcat** which is the categorical substitution of titleyear with 3 levels: 2000-2005, 2006-2010 and 2011-2016. Therefore, we will have two categorical variables (genre and titleyear).  

```{r titleyear-to-categorical, echo=TRUE}
dataset$yearcat<-cut(dataset$titleyear, 
                     c(2000,2005,2010,2016), 
                     include.lowest = TRUE, 
                     labels=c("2000-2005", "2006-2010", "2011-2016"))
```



## Exploratory Data Analysis
In this section we are going to focus in explaining the most interesting conclusions of our data, perform an univariate and multivariate analysis of the variables in order to find outliers and see how each of these variables is related with the gross. We are also going to modify some variables in order to make the linear model perform better on them.


###Movie title

We have performed a cloud of the most relevant words that appear in the movies. To do so, we have removed stopwords and punctuation. We could have also done a stemming process but is not so important for us to do so.
We can see that the top words are words such as: man, love, movie, house, american, life, big, etc.

```{r, echo=FALSE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE}
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")

text <- dataset$movietitle
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
#docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word

# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=50, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
#words that occur at least 4 times
#findFreqTerms(dtm, lowfreq = 4)
#terms that associate with word
#findAssocs(dtm, terms = "man", corlimit = 0.3)
```

###Budget

We can see that there is a very disperse amount of values regarding the budget that range from a minimum of 400 thousand dollars (Napoleon Dynamite) to 300 million dollars (Pirates of the Caribbean: At World's End). Despite how crazy this numbers can appear to be, we have revised them by looking at the budget of this two movies on the interent and are correct. 
Note that this does not imply that all the budgets we have are corrects but it implies that we have to deal with such a range of different values in a same variable.

```{r, message=FALSE, warning=FALSE, include=FALSE}
dataset$movietitle[dataset$budget==400000]
dataset$movietitle[dataset$budget==300000000]
```

```{r, echo=FALSE, fig.height=4, fig.width=12}
par(mfrow=c(1,2))
hist(dataset$budget, main="Histogram of budget")
boxplot(dataset$budget, main="Box Plot of budget")
```

####Relationship between budget and gross

We can see that the revenue is correlated with the budget as we can see in the plot below.
```{r, echo=FALSE, fig.height=4, fig.width=12}
plot(dataset$budget, dataset$gross)
```

###Gross

If we take a look at the gross variable, we can see that in a similar fashion than with budget, we have a range of values that can go from 3330$ with Mi America to Avatar with 760 milions of dollars.

```{r, echo=TRUE, fig.height=4, fig.width=12}
par(mfrow=c(1,3))
boxplot(dataset$gross)
plot(density(dataset$gross), main="Density plot of gross")
hist(dataset$gross)
```


[//]: #No entenc per quÃ¨ vols cap d'aquestes dades.... 
[//]: #explica'm si us plau quin sentit tenen i mirem de incorporar-ho

[//]: #Sample mean
[//]: #```{r, echo=TRUE}
[//]: #(m=mean(dataset$gross))
[//]: #```
[//]: #Sample Sd
[//]: #```{r, echo=TRUE}
[//]: #cat("Sample Sd\n")
[//]: #(s=sd(dataset$gross))
[//]: #```
[//]: #LogLik
[//]: #```{r, echo=TRUE}
[//]: #(loglik=sum(log(dnorm(dataset$gross,mean=mean(dataset$gross),sd=sd(dataset$gross)))))
[//]: #```
[//]: #AIC
[//]: #```{r, echo=TRUE}
[//]: #(AIC=-2*loglik+2*2)
[//]: #```


[//]: ##Plot Quantiles-Quantiles (Empirical-Theorical)
[//]: #```{r, echo=TRUE}
[//]: #par(mfrow=c(1,2))
[//]: #qqplot(qnorm(ppoints(500),mean=m,sd=s),dataset$gross)
[//]: #qqnorm(dataset$gross)
[//]: #```

As we have just seen values from budget and gross are in a bigger scale than the rest of our data. This is a problem when performing a linear model since it adds complexity to the model. In order to avoid so, we are going to scale those variables. We decided to apply $\sf{log_{10}}$ because it is easier to interprate later when showing (insert justification).

[//]: Class comment:
[//]: consider later when it increases that we have this variables in logarithm
[//]: log G = bo + b1 log B + .....
[//]: if we add one unit, we have to consider that we are in logarithm and we should express in exponential...
[//]: is not the same if we consider without log and with log, so we have to consider.
[//]: if we multiply per 10 is easier to later show.

```{r dollars, eval=FALSE, fig.height=4, fig.width=12, include=FALSE}
dataset$gross <- log10(dataset$gross)
dataset$budget <- log10(dataset$budget)
par(mfrow=c(1,2))
plot(density(dataset$gross), main="Density plot of gross")
plot(density(dataset$budget), main="Density plot of budget")
```

Now we can see that even it does not follow a normal distribution completely it starts to look like one and what is more important is that the range of values is smaller for both, budget and gross.


###Duration

In duration film, we see that there is a certain tendency to normality centered around 100 minutes, we consider it as usual. There is a strange observation of 280 minutes for "Gods and General" film. After we check it, we can say that it is not an error but an extreme value. 

```{r, echo=FALSE, fig.height=4, fig.width=12}
par(mfrow=c(1,2))
hist(dataset$duration, main="Histogram of film duration")
boxplot(dataset$duration, main="Box Plot of film duration")
```


####Relationship between duration and gross

We can see that there is not a clear correlation between the duration of a film and its revenue since we can see that transversally to the duration, we have the similar results in gross.
```{r, echo=FALSE, fig.height=4, fig.width=12}
plot(dataset$duration, dataset$gross)
```

[//]:Maybe we could consider passing duration to hours. What do you think about it?

[//]:```{r, echo=FALSE, fig.height=4, fig.width=12}
[//]:#dataset$duration <- dataset$duration/60
[//]:par(mfrow=c(1,2))
[//]:hist(dataset$duration, main="Histogram of film duration")
[//]:boxplot(dataset$duration, main="Box Plot of film duration")
[//]:```

###Title Year

No problems for year, there is a certain expected balanced in years proportion even that we can see a decay in the number of films for 2016.

```{r, echo=FALSE, fig.height=4, fig.width=12}
barplot(table(dataset$titleyear), main="Bar Chart of title year")
```

####Relationship between years and gross
We can see that there is not a strong correlation between the year of release and the gross obtained from those years. Even that there are some years better than others.

```{r, echo=FALSE, fig.height=4, fig.width=12}
plot(dataset$titleyear, dataset$gross)
```

###Directorfl, Actor1fl, Actor2fl, Actor3fl, Castfl

In Director Facebook likes, we see that there is a value which appears in the majority of the cases: In this case, is the 0 value. Apart from this zero value, we see that small number of likes are more common than medium or higher number of likes. 

```{r, echo=FALSE, fig.height=4, fig.width=12}
plot(density(dataset$directorfl), main="Density plot of Director Facebook Likes")
#length(which(dataset$directorfl==0))/length(dataset$directorfl)
```
We can see that the other variables Actor1fl, Actor2fl, Actor3fl, Castfl follow a similar fashion.


####Relationship of Directorfl, Actor1fl, Actor2fl, Actor3fl, Castfl with gross

We can see a trend where the more likes Directors, Acts or Cast are they tend to have more revenue.

```{r, echo=FALSE, fig.height=4, fig.width=12}
par(mfrow=c(2,3))
plot(dataset$directorfl, dataset$gross)
plot(dataset$actor1fl, dataset$gross)
plot(dataset$actor2fl, dataset$gross)
plot(dataset$actor3fl, dataset$gross)
plot(dataset$castfl, dataset$gross)
```

###Facenumber in poster

In face number in film poster, the mean is about 1,6 faces and we can observe an extrem value of 31 in "The Master". We can say once again that it is not an error but an extreme value.

```{r, echo=FALSE, fig.height=4, fig.width=12}
par(mfrow=c(1,3))
plot(dataset$facenumber_in_poster)
#no em molen gens les grÃ fiques que fas per general. No sÃ³n gens indicatives ni sÃ³n clares. el hist no tÃ© sentit
hist(dataset$facenumber_in_poster, main="Histogram of face number")
boxplot(dataset$facenumber_in_poster, main="Box Plot of face number")
```

####Relationship of Facenumber with Gross
```{r, echo=FALSE, fig.height=4, fig.width=12}
plot(dataset$facenumber_in_poster, dataset$gross)
```

###Genre
In genre film we can observe that there are more comedy and drama films than action and terror films. 


```{r, echo=FALSE, fig.height=4, fig.width=12}
par(mfrow=c(1,2))
barplot(table(dataset$genre), main="Bar Chart of film genre")
library("wordcloud")
set.seed(1234)
wordcloud(words = c("Action", "Comedy","Drama", "Terror"), freq = c(112, 365, 330, 133) , min.freq = 50,
          max.words=5, random.order=FALSE, rot.per=0.45, 
          colors=brewer.pal(3, "Dark2"))
```

####Relationship of Genre with Gross

We can see that action films from the dataset tend to have a slightly more income than drama, terror and comedy films. We also can see that there are more outlayers in the comedy genre.

```{r, echo=FALSE, fig.height=4, fig.width=12}
plot(dataset$genre, dataset$gross)
```

## Correlation matrix
In this section we can see the correlation between the varibales. It is a bit of what we have seen but in this case is not only focused with the gross but all the variables. Furthermore, by doing the correlation of the variables, we have a numeric value that says us how correlated two variables are which we did not quantify when doing the exploratory analysis.

We can see that there is a positive correlation between gross and budget variable (0,729). On the other hand there is positive correlation between Cast Facebook Likes and Actor Facebook likes. 

**EXPLICAR MÃS**

```{r pressure, echo=FALSE, message=FALSE, warning=FALSE, fig.height=4, fig.width=12}
pairs(~.,dataset[,-c(1)])
kable(cor(dataset[,-c(1, 5, 12, 13)]), format="latex", booktabs=TRUE) %>% 
  kable_styling(latex_options="scale_down")
```


## Fitting the complete model

```{r, fig.height=4, fig.width=12, message=FALSE, warning=FALSE, include=FALSE}
summary(completeModel<-lm(gross ~ (budget + duration + directorfl + actor1fl + actor2fl 
                                   + actor3fl + castfl + facenumber_in_poster 
                                   + genre)^2, dataset))
```

```{r, echo=TRUE, message=FALSE, warning=FALSE, fig.height=4, fig.width=12}
op<-par(mfrow=c(2,2))
plot(completeModel)
```

## Use the stepwise procedure, by using the BIC criterion, to select the signicant variables

```{r, echo=TRUE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE}
nullModel <- lm(gross ~ 1, dataset)

forwardModel <- step(nullModel, 
                     scope = list(upper=completeModel), 
                     direction="both", criterion = "BIC", 
                     k=log(nrow(dataset)))

backwardModel <- step(completeModel, 
                      scope = list(lower=nullModel), 
                      direction="both", 
                      criterion = "BIC", 
                      k=log(nrow(dataset)))


summary(forwardModel)
summary(backwardModel)
```

## Check the presence of multicollinearity. If there is some non-interaction multicollinearity in the model, make the corresponding corrections.
```{r, echo=TRUE, fig.height=4, fig.width=12, message=FALSE, warning=FALSE}
car::vif(forwardModel)
car::vif(backwardModel)

```


